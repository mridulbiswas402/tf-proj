{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capsule1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zmQwP2-_Gl0A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine import data_adapter"
      ],
      "metadata": {
        "id": "RkpRtymlqAb3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FTzA6fy_Gvnp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "njM193-baa26"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def squash(v,epsilon=1e-7,axis=-1):\n",
        "    sqnrm=tf.reduce_sum(tf.square(v), axis=axis,keepdims=True)\n",
        "    nrm=tf.sqrt(sqnrm + epsilon) #safe norm to avoid divide by zero.\n",
        "    sqsh_factor = sqnrm / (1. + sqnrm)\n",
        "    unit_vect = v / nrm\n",
        "    return sqsh_factor*unit_vect\n",
        "\n",
        "@tf.function\n",
        "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False):\n",
        "        squared_norm = tf.reduce_sum(tf.square(s),axis=axis,keepdims=keep_dims)\n",
        "        return tf.sqrt(squared_norm + epsilon)"
      ],
      "metadata": {
        "id": "I3-j_MOkaCtf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#downloading data.\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "#train data\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
        "                                                            shuffle=True,\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            image_size=IMG_SIZE)\n",
        "\n",
        "#validation model.\n",
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
        "                                                                 shuffle=True,\n",
        "                                                                 batch_size=BATCH_SIZE,\n",
        "                                                                 image_size=IMG_SIZE)\n",
        "\n",
        "\"\"\" #viewing some sample from the dataset.\n",
        "class_names = train_dataset.class_names\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "  for i in range(3):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")\n",
        "    \"\"\"\n",
        "\n",
        "# creating test data.\n",
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "test_dataset = validation_dataset.take(val_batches // 5)\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
        "\n",
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))\n",
        "\n",
        "\n",
        "#y_train=tf.keras.utils.to_categorical(y_train)\n",
        "#y_test=tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES7neHl9Gx-o",
        "outputId": "8ead21b0-4d75-4a65-90af-66998300ad24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 0s 0us/step\n",
            "68616192/68606236 [==============================] - 0s 0us/step\n",
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Number of validation batches: 26\n",
            "Number of test batches: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#optimization parameter setting.\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "1IaqLHuAwxYt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caps1_n_maps = 32\n",
        "caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsules\n",
        "caps1_n_dims = 8\n",
        "\n",
        "# digit capsule layer\n",
        "caps2_n_caps = 10 # 10 capsule each digit.\n",
        "caps2_n_dims = 16 # each of the 10 capsules are of 16 dims.\n"
      ],
      "metadata": {
        "id": "PL71lMZzG1Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Primary_caps_layer(tf.keras.layers.Layer):\n",
        "  \"\"\" caps_n(i) --> no of capsule in ith layer \n",
        "      caps_dim(i) --> dimension of capsule in ith layer. \n",
        "      \n",
        "      primary_caps_layer output shape = [batch_size,caps_n,caps_dim]\"\"\"\n",
        "\n",
        "  def __init__(self,caps_n=1152,k1=256,k2=256,k_s1=9,k_s2=5,s1=1,s2=3):\n",
        "    super(Primary_caps_layer, self).__init__()\n",
        "    self.caps_n=caps_n  # no of capsule in this layer.\n",
        "    #self.caps_dim=caps_dim # dim of each capsule in this layer\n",
        "    self.k1=k1\n",
        "    self.k2=k2\n",
        "    self.k_s1=k_s1\n",
        "    self.k_s2=k_s2\n",
        "    self.s1=s1\n",
        "    self.s2=s2\n",
        "    self.conv1=tf.keras.layers.Conv2D(k1,kernel_size=k_s1,strides=s1,padding='valid',activation='relu') \n",
        "    self.conv2=tf.keras.layers.Conv2D(k2,kernel_size=k_s2,strides=s2,padding='valid',activation='relu')\n",
        "\n",
        "  def call(self, input_tensor):\n",
        "    x=self.conv1(input_tensor)\n",
        "    x=self.conv2(x)\n",
        "    assert x.shape[1]*x.shape[1]*self.k2==self.caps_n*self.caps_dim\n",
        "    x=tf.reshape(x,[self.batch_size,self.caps_n,self.caps_dim])\n",
        "    return squash(x)\n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.batch_size=input_shape[0]\n",
        "    tmp=int(((input_shape[1]-self.k_s1)/self.s1))+1\n",
        "    self.conv1_output_shape=[input_shape[0],tmp,tmp,self.k1]\n",
        "    tmp=int(((tmp-self.k_s2)/self.s2))+1\n",
        "    self.conv2_output_shape=[input_shape[0],tmp,tmp,self.k2]\n",
        "    tmp1=tmp*tmp*self.k2\n",
        "    self.caps_n=self.caps_n-(tmp1%self.caps_n)\n",
        "    self.caps_dim=int((tmp*tmp*self.k2)/self.caps_n);\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "UJZ0c0hDKstw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Digit_caps_layer(tf.keras.layers.Layer):\n",
        "  \"\"\" caps_n(i) --> no of capsule in ith layer \n",
        "      caps_dim(i) --> dimension of capsule in ith layer. \n",
        "      and we assume this is ith layer. \n",
        "      output.shape of ith layer = [batch_size, 1,caps_n(i),caps_dim(i), 1]\"\"\"\n",
        "\n",
        "  def __init__(self,caps_dim=16,caps_n=10,r=3):\n",
        "    super(Digit_caps_layer,self).__init__()\n",
        "    self.caps_n=caps_n # no of capsule.\n",
        "    self.caps_dim=caps_dim # dim of each capsule.\n",
        "    self.r=r # no of iteration in routing by agreement algorithm.\n",
        "    \n",
        "  def build(self,input_shape): # input_shape = [batch_size,caps_n(i-1),caps_dim(i-1)] \n",
        "    self.W = tf.Variable(initial_value=tf.random.normal(\n",
        "    shape=(1, input_shape[1], self.caps_n, self.caps_dim, input_shape[-1]),\n",
        "    stddev=0.1, dtype=tf.float32),\n",
        "    trainable=True)  #weigth initialization for this layer W.shape=[1,caps_n(i-1),caps_n(i),caps_dim(i),caps_dim(i-1)].\n",
        "\n",
        "  def call(self,input_tensor): #input_tensor.shape=[batch_size,caps_n(i-1),caps_dim(i-1)]\n",
        "    batch_size = input_tensor.shape[0]\n",
        "    W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1]) # replicating the weights for parallel processing of a batch.\n",
        "    \"\"\" W_tiled.shape=[batch_size,caps_n(i-1),caps_n(i),caps_dim(i),caps_dim(i-1)] \"\"\"\n",
        "\n",
        "    caps_output_expanded = tf.expand_dims(input_tensor, -1) # converting last dim to a column vector.\n",
        "    \"\"\" the above step change the input shape from \n",
        "        [batch_size,caps_n(i-1),caps_dim(i-1)] --> [batch_size,caps_n(i-1),caps_dim(i-1),1]\"\"\"\n",
        "\n",
        "    caps_output_tile = tf.expand_dims(caps_output_expanded, 2)\n",
        "    \"\"\" the above step change the input shape from \n",
        "        [batch_size,caps_n(i-1),caps_dim(i-1),1] --> [batch_size,caps_n(i-1),1,caps_dim(i-1),1]\"\"\"\n",
        "\n",
        "    caps_output_tiled = tf.tile(caps_output_tile, [1, 1, self.caps_n, 1, 1]) # replicating the input capsule vector for every output capsule.\n",
        "    \" i.e [batch_size,caps_n(i-1),1,caps_dim(i-1),1] --> [batch_size,caps_n(i-1),caps_n(i),1,caps_dim(i-1),1]\"\n",
        "\n",
        "    caps_predicted = tf.matmul(W_tiled, caps_output_tiled) # this is performing element wise tf.matmul() operation.\n",
        "    \"\"\" caps_predicted.shape = [1,caps_n(i-1),caps_n(i),caps_dim(i),1]\"\"\"\n",
        "\n",
        "    \"\"\" dynamic routing \"\"\"\n",
        "    raw_weights = tf.zeros([batch_size,input_tensor.shape[1] , self.caps_n, 1, 1]) # non trainable weights.\n",
        "    \"\"\" raw_weights.shape=[batch_size,caps_n(i-1) ,caps_n(i), 1, 1]\"\"\"\n",
        "\n",
        "    r=self.r\n",
        "    while(r):\n",
        "      r-=1\n",
        "      routing_weights = tf.nn.softmax(raw_weights,axis=2)\n",
        "      \"\"\" [batch_size,caps_n(i-1) ,caps_n(i), 1, 1]  softmax applied along the pointed dim.\n",
        "                                       ^                                                   \"\"\"\n",
        "\n",
        "      weighted_predictions = tf.multiply(routing_weights, caps_predicted)\n",
        "      \"\"\" weighted_predictions.shape = [batch_size, caps_n(i-1),caps_n(i),caps_dim(i), 1]\"\"\"\n",
        "\n",
        "      weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keepdims=True)\n",
        "      \"\"\" [batch_size,caps_n(i-1) ,caps_n(i),caps_dim(i), 1]  sum applied along the pointed dim.\n",
        "                           ^                                                               \n",
        "      therefore weighted_sum.shape=[batch_size,1 ,caps_n(i),caps_dim(i), 1]\"\"\"\n",
        "\n",
        "      v = squash(weighted_sum, axis=-2) #normalize to unit length vector.\n",
        "      v_tiled = tf.tile(v, [1, input_tensor.shape[1], 1, 1, 1])\n",
        "      \"\"\" v_tiled.shape=[batch_size,caps_n(i-1),caps_n(i),caps_dim(i), 1]\"\"\"\n",
        "\n",
        "      agreement = tf.matmul(caps_predicted, v_tiled,transpose_a=True)\n",
        "      \"\"\" agreement.shape=[batch_size,caps_n(i-1),caps_n(i), 1, 1]\"\"\"\n",
        "\n",
        "      if(r>0):\n",
        "          routing_weights+=agreement\n",
        "      else:\n",
        "          return v"
      ],
      "metadata": {
        "id": "Upn8S10ai3M-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "class Caps_net(tf.keras.Model):\n",
        "\n",
        "  def __init__(self,no_classes=10,batch_size=32):\n",
        "    super(Caps_net,self).__init__()\n",
        "    self.batch_size=batch_size\n",
        "    self.pri_layer=Primary_caps_layer(caps_n=1152,k1=256,k2=256,k_s1=9,k_s2=5,s1=1,s2=3,batch_size=self.batch_size)\n",
        "    #self.intrm_layer=Digit_caps_layer(caps_dim=8,caps_n=10,r=3)\n",
        "    self.dig_layer=Digit_caps_layer(caps_dim=8,caps_n=no_classes,r=3,batch_size=self.batch_size)\n",
        "    \n",
        "\n",
        "  def call(self,input_tensor):\n",
        "    x = self.pri_layer(input_tensor) #x.shape=[batch_size,caps_n(i),caps_dim(i)]\n",
        "    #x = self.intrm_layer(x)\n",
        "    #x = tf.squeeze(x, axis=[1,4])\n",
        "    x = self.dig_layer(x) #x.shape=[batch_size, 1,caps_n(i),caps_dim(i), 1]\n",
        "\n",
        "    \"\"\"The lengths of the output vectors represent the class probabilities, \n",
        "       so we could just use tf.norm() to compute them,\"\"\"\n",
        "    x = safe_norm(x, axis=-2) #x.shape=[batch_size,1,caps_n(i-1),1]\n",
        "\n",
        "    x = tf.nn.softmax(x,axis=2) #converting those probabilities to prob dist.\n",
        "    x = tf.squeeze(x, axis=[1,3]) #reducing the extra dims. therefore the output shape =[batch_size,caps_n(i-1)] \n",
        "    return x\n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.batch_size=input_shape[0];\n",
        "\n",
        "  \"\"\" custom training loop \"\"\"\n",
        "  def train_step(self,data):\n",
        "    x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n",
        "    y=tf.keras.utils.to_categorical(y)\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = self(x, training=True)  # Forward pass\n",
        "        # Compute the loss value\n",
        "        # (the loss function is configured in `compile()`)\n",
        "        loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}  \n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Ehw2bjCPbCLF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model=Caps_net(no_classes=2)"
      ],
      "metadata": {
        "id": "LGqZX4_fhSS0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zWawSflNO1Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "model.compile(\n",
        "          loss      = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "          metrics   = tf.keras.metrics.CategoricalAccuracy(),\n",
        "          optimizer = tf.keras.optimizers.Adam())\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lWifrRJdb7Cl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output of the tmp model. \n",
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "\n"
      ],
      "metadata": {
        "id": "TE_237C6dVG7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch.shape"
      ],
      "metadata": {
        "id": "k4Q-BchI86fR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0226d0-54c8-4954-fea2-79ebc15c8a62"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 160, 160, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pri=Primary_caps_layer(caps_n=256,k1=64,k2=64,k_s1=9,k_s2=5,s1=1,s2=3)\n",
        "dig=Digit_caps_layer(caps_dim=8,caps_n=2,r=3)"
      ],
      "metadata": {
        "id": "9bZSATdWZmXa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=pri(image_batch)"
      ],
      "metadata": {
        "id": "DIs_EoWFZ8dF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p47vdgXvaKRs",
        "outputId": "89f510bd-013e-4b67-f3ef-980d1a05a55e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 256, 625])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=dig(x)"
      ],
      "metadata": {
        "id": "bidZw8HvaWxs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lD-sPQhaZQ0",
        "outputId": "c8d078a1-35f9-44d9-8d5c-02ca5a1fb064"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 1, 2, 8, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHtBY4TfajZt",
        "outputId": "eb44c487-e8fb-4200-89c6-fc027c56ba36"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 8, 1), dtype=float32, numpy=\n",
              "array([[[[-0.38722607],\n",
              "         [-0.10100831],\n",
              "         [-0.33626333],\n",
              "         [-0.00649191],\n",
              "         [-0.04269022],\n",
              "         [ 0.5096647 ],\n",
              "         [ 0.03618015],\n",
              "         [ 0.17151405]],\n",
              "\n",
              "        [[ 0.23256193],\n",
              "         [-0.11151747],\n",
              "         [ 0.28388774],\n",
              "         [-0.5194642 ],\n",
              "         [ 0.06661782],\n",
              "         [-0.22748002],\n",
              "         [-0.33919474],\n",
              "         [-0.07836808]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = safe_norm(x, axis=-2) #x.shape=[batch_size,1,caps_n(i-1),1]\n",
        "print(x.shape)\n",
        "x = tf.nn.softmax(x,axis=2) #converting those probabilities to prob dist.\n",
        "print(x.shape)\n",
        "x = tf.squeeze(x, axis=[1,3]) #reducing the extra dims. therefore the output shape =[batch_size,caps_n(i-1)] \n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Asbf0jkblQw",
        "outputId": "dfb839d6-ceb8-432e-ea47-5f872fc7f801"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 1, 2, 1)\n",
            "(32, 1, 2, 1)\n",
            "(32, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuV_kttIcEAx",
        "outputId": "a26413c1-3210-41db-d8cc-3ce64ce16254"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 2), dtype=float32, numpy=\n",
              "array([[0.49527785, 0.5047222 ],\n",
              "       [0.48035017, 0.5196498 ],\n",
              "       [0.49423286, 0.50576717],\n",
              "       [0.49328157, 0.5067185 ],\n",
              "       [0.5099131 , 0.49008685],\n",
              "       [0.53202593, 0.4679741 ],\n",
              "       [0.5188192 , 0.48118076],\n",
              "       [0.48478884, 0.5152112 ],\n",
              "       [0.5120314 , 0.48796862],\n",
              "       [0.5013908 , 0.49860916],\n",
              "       [0.50233954, 0.4976605 ],\n",
              "       [0.51419985, 0.48580015],\n",
              "       [0.49786547, 0.5021345 ],\n",
              "       [0.4905074 , 0.50949264],\n",
              "       [0.5292736 , 0.4707264 ],\n",
              "       [0.50634205, 0.49365792],\n",
              "       [0.4902343 , 0.5097657 ],\n",
              "       [0.5024426 , 0.4975574 ],\n",
              "       [0.4692447 , 0.53075534],\n",
              "       [0.5054724 , 0.49452758],\n",
              "       [0.4696343 , 0.53036565],\n",
              "       [0.47749606, 0.5225039 ],\n",
              "       [0.47772518, 0.52227485],\n",
              "       [0.52168375, 0.47831622],\n",
              "       [0.5056131 , 0.4943869 ],\n",
              "       [0.516404  , 0.48359606],\n",
              "       [0.48396993, 0.51603   ],\n",
              "       [0.47038445, 0.5296156 ],\n",
              "       [0.4950577 , 0.5049423 ],\n",
              "       [0.5128532 , 0.4871467 ],\n",
              "       [0.5132649 , 0.48673514],\n",
              "       [0.4987992 , 0.50120074]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Caps_net(tf.keras.Model):\n",
        "\n",
        "  def __init__(self,no_classes=10):\n",
        "    super(Caps_net,self).__init__()\n",
        "    self.pri_layer=Primary_caps_layer(caps_n=256,k1=64,k2=64,k_s1=9,k_s2=5,s1=1,s2=3)\n",
        "    self.dig_layer=Digit_caps_layer(caps_dim=8,caps_n=no_classes,r=3)\n",
        "    \n",
        "\n",
        "  def call(self,input_tensor):\n",
        "    x = self.pri_layer(input_tensor) #x.shape=[batch_size,caps_n(i),caps_dim(i)]\n",
        "    x = self.dig_layer(x) #x.shape=[batch_size, 1,caps_n(i),caps_dim(i), 1]\n",
        "    x = safe_norm(x, axis=-2) #x.shape=[batch_size,1,caps_n(i-1),1]\n",
        "    x = tf.nn.softmax(x,axis=2) #converting those probabilities to prob dist.\n",
        "    x = tf.squeeze(x, axis=[1,3]) #reducing the extra dims. therefore the output shape =[batch_size,caps_n(i-1)] \n",
        "    return x\n",
        "\n",
        "  def train_step(self,data):\n",
        "    x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n",
        "    y=tf.keras.utils.to_categorical(y)\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = self(x, training=True)  # Forward pass\n",
        "        # Compute the loss value\n",
        "        # (the loss function is configured in `compile()`)\n",
        "        loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}  \n"
      ],
      "metadata": {
        "id": "NLWBS43pcFzx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Caps_net(no_classes=2)"
      ],
      "metadata": {
        "id": "yJz60-4JpgBb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(image_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hymMQntqppSj",
        "outputId": "f9b817be-4934-4da7-dd45-da5b12fcc4be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 2), dtype=float32, numpy=\n",
              "array([[0.47808638, 0.5219137 ],\n",
              "       [0.5043702 , 0.49562973],\n",
              "       [0.49857965, 0.50142026],\n",
              "       [0.515404  , 0.484596  ],\n",
              "       [0.48895067, 0.51104933],\n",
              "       [0.5070465 , 0.49295345],\n",
              "       [0.50374866, 0.49625137],\n",
              "       [0.5033982 , 0.49660185],\n",
              "       [0.4966536 , 0.50334644],\n",
              "       [0.4947047 , 0.5052953 ],\n",
              "       [0.48524812, 0.51475185],\n",
              "       [0.4881652 , 0.5118348 ],\n",
              "       [0.4909044 , 0.5090956 ],\n",
              "       [0.50118744, 0.49881256],\n",
              "       [0.5207015 , 0.47929847],\n",
              "       [0.49168444, 0.50831556],\n",
              "       [0.52116555, 0.47883442],\n",
              "       [0.5291591 , 0.47084093],\n",
              "       [0.5165412 , 0.4834588 ],\n",
              "       [0.49379814, 0.5062019 ],\n",
              "       [0.51503056, 0.48496944],\n",
              "       [0.55607474, 0.44392523],\n",
              "       [0.5044899 , 0.49551   ],\n",
              "       [0.5177015 , 0.4822985 ],\n",
              "       [0.5055316 , 0.4944684 ],\n",
              "       [0.46362445, 0.53637546],\n",
              "       [0.51964074, 0.48035932],\n",
              "       [0.50169176, 0.49830827],\n",
              "       [0.48984656, 0.5101534 ],\n",
              "       [0.48894298, 0.511057  ],\n",
              "       [0.50070864, 0.49929142],\n",
              "       [0.50972784, 0.49027222]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"customize training loop.\"\"\"\n",
        "\n",
        "# Instantiate an optimizer to train the model.\n",
        "base_learning_rate = 0.0001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
        "# Instantiate a loss function.\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Prepare the metrics.\n",
        "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "metadata": {
        "id": "6F_P1WSFqT2y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        y_batch_train=tf.keras.utils.to_categorical(y_batch_train)\n",
        "        if(x_batch_train.shape[0]==32): #@ instant hack (needed to be fixed.)\n",
        "          with tf.GradientTape() as tape:\n",
        "              logits = model(x_batch_train)\n",
        "              loss_value = loss_fn(y_batch_train, logits)\n",
        "          grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "          optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "          # Update training metric.\n",
        "          train_acc_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "          \"\"\"# Log every 200 batches.\n",
        "          if step % 200 == 0:\n",
        "              print(\n",
        "                  \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                  % (step, float(loss_value))\n",
        "              )\n",
        "              print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\"\"\"\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in validation_dataset:\n",
        "      if(x_batch_val.shape[0]==32): #@ instant hack (needed to be fixed.)\n",
        "        val_logits = model(x_batch_val)\n",
        "        # Update val metrics\n",
        "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpS74FPep3DL",
        "outputId": "bfb1ba9a-4f18-4bda-b2e1-76c102c0f55d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training acc over epoch: 0.5015\n",
            "Validation acc: 0.2992\n",
            "Time taken: 410.74s\n",
            "\n",
            "Start of epoch 1\n",
            "Training acc over epoch: 0.5318\n",
            "Validation acc: 0.3762\n",
            "Time taken: 362.87s\n",
            "\n",
            "Start of epoch 2\n",
            "Training acc over epoch: 0.5494\n",
            "Validation acc: 0.6025\n",
            "Time taken: 349.25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step=10\n",
        "batch_size=32\n",
        "print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1-40-70um88",
        "outputId": "69b018df-fe1d-49e5-d815-e5075b4f36f3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seen so far: 352 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DU1COaLvu7pQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}