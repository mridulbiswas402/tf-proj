{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "fOGVV6nDtSq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fJ6tSixatSmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = tf.math.reduce_sum(tf.math.square(x), axis, keepdims=True) + keras.backend.epsilon()\n",
        "    scale = tf.math.sqrt(s_squared_norm) / (1 + s_squared_norm)\n",
        "    return scale * x\n",
        "\n",
        "@tf.function\n",
        "def margin_loss(y_true, y_pred):\n",
        "    lamb, margin = 0.5, 0.1\n",
        "    return tf.math.reduce_sum((y_true * tf.math.square(tf.nn.relu(1 - margin - y_pred)) + lamb * (\n",
        "        1 - y_true) * tf.math.square(tf.nn.relu(y_pred - margin))), axis=-1)\n",
        "\n",
        "@tf.function\n",
        "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False):\n",
        "        squared_norm = tf.reduce_sum(tf.square(s),axis=axis,keepdims=keep_dims)\n",
        "        return tf.sqrt(squared_norm + epsilon)"
      ],
      "metadata": {
        "id": "BKyd89txbmFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c1=tf.keras.layers.Conv2D(16,kernel_size=5,strides=2,padding='valid',activation='relu')\n",
        "c2=tf.keras.layers.Conv2D(32,kernel_size=5,strides=2,padding='valid',activation='relu')\n",
        "c3=tf.keras.layers.Conv2D(64,kernel_size=5,strides=2,padding='valid',activation='relu')\n",
        "c4=tf.keras.layers.Conv2D(128,kernel_size=5,strides=1,padding='valid',activation='relu')\n",
        "dc1=tf.keras.layers.DepthwiseConv2D(kernel_size=9,strides=(1, 1),padding='valid',activation='relu')"
      ],
      "metadata": {
        "id": "2bJH1-kWbmBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Capsule(keras.layers.Layer):\n",
        "   \n",
        "\n",
        "    def __init__(self,\n",
        "                 num_capsule,\n",
        "                 dim_capsule,\n",
        "                 routings=3,\n",
        "                 **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.caps_n = num_capsule\n",
        "        self.caps_dim = dim_capsule\n",
        "        self.r = routings\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "        'num_capsule':  self.caps_n,\n",
        "        'dim_capsule' : self.caps_dim,\n",
        "        'routings':  self.r,      \n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \n",
        "        self.W = self.add_weight(name='W',\n",
        "                    shape=[1, input_shape[1], self.caps_n, self.caps_dim, input_shape[-1]],\n",
        "                    dtype=tf.float32,\n",
        "                    initializer='glorot_uniform',\n",
        "                    trainable=True)\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        batch_size = input_tensor.shape[0]\n",
        "        \n",
        "        W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1]) # replicating the weights for parallel processing of a batch.\n",
        "        \"\"\" W_tiled.shape=[batch_size,caps_n(i-1),caps_n(i),caps_dim(i),caps_dim(i-1)] \"\"\"\n",
        "\n",
        "        caps_output_expanded = tf.expand_dims(input_tensor, -1) # converting last dim to a column vector.\n",
        "        \"\"\" the above step change the input shape from \n",
        "            [batch_size,caps_n(i-1),caps_dim(i-1)] --> [batch_size,caps_n(i-1),caps_dim(i-1),1]\"\"\"\n",
        "\n",
        "        caps_output_tile = tf.expand_dims(caps_output_expanded, 2)\n",
        "        \"\"\" the above step change the input shape from \n",
        "            [batch_size,caps_n(i-1),caps_dim(i-1),1] --> [batch_size,caps_n(i-1),1,caps_dim(i-1),1]\"\"\"\n",
        "\n",
        "        caps_output_tiled = tf.tile(caps_output_tile, [1, 1, self.caps_n, 1, 1]) # replicating the input capsule vector for every output capsule.\n",
        "        \"\"\" i.e [batch_size,caps_n(i-1),1,caps_dim(i-1),1] --> [batch_size,caps_n(i-1),caps_n(i),1,caps_dim(i-1),1]\"\"\"\n",
        "\n",
        "        caps_predicted = tf.matmul(W_tiled, caps_output_tiled) # this is performing element wise tf.matmul() operation.\n",
        "        \"\"\" caps_predicted.shape = [1,caps_n(i-1),caps_n(i),caps_dim(i),1]\"\"\"\n",
        "\n",
        "        \"\"\" dynamic routing \"\"\"\n",
        "        raw_weights = tf.zeros([batch_size,input_tensor.shape[1] , self.caps_n, 1, 1]) # non trainable weights.\n",
        "        \"\"\" raw_weights.shape=[batch_size,caps_n(i-1) ,caps_n(i), 1, 1]\"\"\"\n",
        "\n",
        "        r=self.r\n",
        "        while(r):\n",
        "          r-=1\n",
        "          routing_weights = tf.nn.softmax(raw_weights,axis=2)\n",
        "          \"\"\" [batch_size,caps_n(i-1) ,caps_n(i), 1, 1]  softmax applied along the pointed dim.\n",
        "                                           ^                                                   \"\"\"\n",
        "\n",
        "          weighted_predictions = tf.multiply(routing_weights, caps_predicted)\n",
        "          \"\"\" weighted_predictions.shape = [batch_size, caps_n(i-1),caps_n(i),caps_dim(i), 1]\"\"\"\n",
        "\n",
        "          weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keepdims=True)\n",
        "          \"\"\" [batch_size,caps_n(i-1) ,caps_n(i),caps_dim(i), 1]  sum applied along the pointed dim.\n",
        "                               ^                                                               \n",
        "          therefore weighted_sum.shape=[batch_size,1 ,caps_n(i),caps_dim(i), 1]\"\"\"\n",
        "\n",
        "          v = squash(weighted_sum, axis=-2) #normalize to unit length vector.\n",
        "          v_tiled = tf.tile(v, [1, input_tensor.shape[1], 1, 1, 1])\n",
        "          \"\"\" v_tiled.shape=[batch_size,caps_n(i-1),caps_n(i),caps_dim(i), 1]\"\"\"\n",
        "\n",
        "          agreement = tf.matmul(caps_predicted, v_tiled,transpose_a=True)\n",
        "          \"\"\" agreement.shape=[batch_size,caps_n(i-1),caps_n(i), 1, 1]\"\"\"\n",
        "\n",
        "          if(r>0):\n",
        "              routing_weights+=agreement\n",
        "          else:\n",
        "              v = tf.squeeze(v, axis=[1,4])\n",
        "              return v"
      ],
      "metadata": {
        "id": "fRDpS2cqbl81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Capsule(32,16)"
      ],
      "metadata": {
        "id": "WyvP4TMjcHu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=keras.Input(shape=(128, 128, 3), batch_size=32)"
      ],
      "metadata": {
        "id": "3YR6X9lobl59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBMHtk_ev5Zt",
        "outputId": "afd501ae-c935-4a77-c78c-6126aa3c26a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 128, 128, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=dc1(c4(c3(c2(c1(X)))))"
      ],
      "metadata": {
        "id": "3gnmvTUzwHx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z=tf.reshape(z,(-1,16,8))"
      ],
      "metadata": {
        "id": "vgeIG_HYwQVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8iJes-Wv5Ut",
        "outputId": "33970b0f-ec07-4203-d0a8-3af22d45d74c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(32, 1, 32, 16, 1) dtype=float32 (created by layer 'capsule_11')>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = keras.Input(shape=(128, 128, 3), batch_size=32)\n",
        "x=c1(model_input)\n",
        "x=c2(x)\n",
        "x=c3(x)\n",
        "x=c4(x)\n",
        "x=dc1(x)\n",
        "x=tf.reshape(x,[-1,16,8])\n",
        "model_output = model(x)"
      ],
      "metadata": {
        "id": "2omDomULxWtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = keras.Model(model_input, model_output, name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BsFumHXxk3P",
        "outputId": "961b4605-7c38-4ced-8160-b08fdbaffd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(32, 128, 128, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             multiple                  1216      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           multiple                  12832     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           multiple                  51264     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           multiple                  204928    \n",
            "                                                                 \n",
            " depthwise_conv2d (Depthwise  multiple                 10496     \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " tf.reshape_14 (TFOpLambda)  (32, 16, 8)               0         \n",
            "                                                                 \n",
            " capsule_13 (Capsule)        (32, 32, 16)              65536     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 346,272\n",
            "Trainable params: 346,272\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o=encoder(keras.Input(shape=(128, 128, 3), batch_size=16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7JsMlI71tvm",
        "outputId": "924159cb-dcc3-4017-fe16-5a86a695bc37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (32, 128, 128, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 128, 128, 3), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (16, 128, 128, 3).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O9chzKUn5oHj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}