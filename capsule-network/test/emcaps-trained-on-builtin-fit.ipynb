{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_probability as tfp\nfrom tensorflow_probability import distributions as tfd\n\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom scipy import random\n\nimport os\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-05T10:37:44.695369Z","iopub.execute_input":"2022-11-05T10:37:44.695837Z","iopub.status.idle":"2022-11-05T10:37:57.587256Z","shell.execute_reply.started":"2022-11-05T10:37:44.695748Z","shell.execute_reply":"2022-11-05T10:37:57.586287Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef squash(x, axis=-1):\n    s_squared_norm = tf.math.reduce_sum(tf.math.square(x), axis, keepdims=True) + keras.backend.epsilon()\n    scale = tf.math.sqrt(s_squared_norm) / (1 + s_squared_norm)\n    return scale * x\n\n@tf.function\ndef margin_loss(y_true, y_pred):\n    lamb, margin = 0.5, 0.1\n    return tf.math.reduce_sum((y_true * tf.math.square(tf.nn.relu(1 - margin - y_pred)) + lamb * (\n        1 - y_true) * tf.math.square(tf.nn.relu(y_pred - margin))), axis=-1)\n\n#@tf.function\ndef safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False):\n        squared_norm = tf.reduce_sum(tf.square(s),axis=axis,keepdims=keep_dims)\n        return tf.sqrt(squared_norm + epsilon)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:38:01.222260Z","iopub.execute_input":"2022-11-05T10:38:01.222870Z","iopub.status.idle":"2022-11-05T10:38:01.231769Z","shell.execute_reply.started":"2022-11-05T10:38:01.222832Z","shell.execute_reply":"2022-11-05T10:38:01.230378Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Capsule(keras.layers.Layer):\n   \n\n    def __init__(self,\n                 num_capsule,\n                 dim_capsule,\n                 routings=3,\n                 **kwargs):\n        super(Capsule, self).__init__(**kwargs)\n        self.caps_n = num_capsule\n        self.caps_dim = dim_capsule\n        self.r = routings\n\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n        'num_capsule':  self.caps_n,\n        'dim_capsule' : self.caps_dim,\n        'routings':  self.r,      \n        })\n        return config\n\n    def build(self, input_shape):\n\n        self.W = self.add_weight(name='W',\n                    shape=[1, input_shape[1], self.caps_n, self.caps_dim, input_shape[-1]],\n                    dtype=tf.float64,\n                    initializer='glorot_uniform',\n                    trainable=True)\n        \n        \n    def call(self, input_tensor):\n        assert input_tensor.shape[2]==self.caps_dim\n        input_tensor=tf.cast(input_tensor,dtype=tf.float64)\n        assert input_tensor.dtype==tf.float64\n        batch_size = input_tensor.shape[0]\n        n=input_tensor.shape[1]\n        k=self.caps_n\n        d=self.caps_dim\n        \n        W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1]) # replicating the weights for parallel processing of a batch.\n        \"\"\" W_tiled.shape=[batch_size,caps_n(i-1),caps_n(i),caps_dim(i),caps_dim(i-1)] \"\"\"\n\n        caps_output_expanded = tf.expand_dims(input_tensor, -1) # converting last dim to a column vector.\n        \"\"\" the above step change the input shape from \n            [batch_size,caps_n(i-1),caps_dim(i-1)] --> [batch_size,caps_n(i-1),caps_dim(i-1),1]\"\"\"\n\n        caps_output_tile = tf.expand_dims(caps_output_expanded, 2)\n        \"\"\" the above step change the input shape from \n            [batch_size,caps_n(i-1),caps_dim(i-1),1] --> [batch_size,caps_n(i-1),1,caps_dim(i-1),1]\"\"\"\n\n        caps_output_tiled = tf.tile(caps_output_tile, [1, 1, self.caps_n, 1, 1]) # replicating the input capsule vector for every output capsule.\n        \"\"\" i.e [batch_size,caps_n(i-1),1,caps_dim(i-1),1] --> [batch_size,caps_n(i-1),caps_n(i),1,caps_dim(i-1),1]\"\"\"\n\n        caps_predicted = tf.matmul(W_tiled, caps_output_tiled) # this is performing element wise tf.matmul() operation.\n        \"\"\" caps_predicted.shape = [1,caps_n(i-1),caps_n(i),caps_dim(i),1]\"\"\"\n\n        \"\"\" dynamic routing \"\"\"\n        #initialization step.\n        \n        pi=np.ones([batch_size,k])/k\n        mu=np.random.rand(batch_size,k,d)\n        sigma=np.ones([batch_size,k,d])\n        R=np.zeros(shape=(batch_size,n,k))\n\n\n        pi=tf.convert_to_tensor(pi,dtype=tf.float64)\n        mu=tf.convert_to_tensor(mu,dtype=tf.float64)\n        sigma=tf.convert_to_tensor(sigma,dtype=tf.float64)\n        R=tf.convert_to_tensor(R,dtype=tf.float64)\n\n\n        r=self.r\n        while(r):\n          r=r-1\n          # E-step.\n          \n          x_tmp=tf.expand_dims(input_tensor,axis=1) # x.shape==[b,n,d]\n          x_tmp=tf.tile(x_tmp,[1,k,1,1]) # x_tmp.shape==[b,k,n,d]\n\n          mu_tmp=tf.expand_dims(mu,axis=2) # mu.shape==[b,k,d]\n          mu_tmp=tf.tile(mu_tmp,[1,1,n,1])   # mu_tmp.shape==[b,k,n,d]\n\n          sig_tmp=tf.expand_dims(sigma,axis=2) # sigma.shape==[b,k,d]\n          sig_tmp=tf.tile(sig_tmp,[1,1,n,1])   # sig_tmp.shape == [b,k,n,d]\n\n          #print(x_tmp.shape,mu_tmp.shape,sig_tmp.shape)\n\n          N = tfd.MultivariateNormalDiag(loc=mu_tmp,scale_diag=sig_tmp).prob(x_tmp)\n          #print(N.shape)\n          N = pi[:,:,None]*N\n          N = N/tf.expand_dims(tf.reduce_sum(N,axis=1),axis=1)\n          R = tf.transpose(N,perm=[0,2,1])\n\n          # M-step\n          \n          # updating pi.\n          N_k = tf.reduce_sum(R,axis=1)\n          pi = N_k/n\n\n          # updating mu.\n          mu = tf.matmul(tf.transpose(R,perm=[0,2,1]),input_tensor)\n          mu = mu/N_k[:,:,None]\n\n          # updating sigma.\n\n          mu_tmp=tf.expand_dims(mu,axis=2)\n          mu_tmp=tf.tile(mu_tmp,[1,1,n,1])\n\n          x_tmp=x_tmp-mu_tmp\n          x_tmp=tf.square(x_tmp)\n\n\n          R_T=tf.transpose(R,perm=[0,2,1])\n\n          x_tmp = tf.multiply(tf.reshape(R_T,[batch_size,k,n,1]),x_tmp)\n          sigma = tf.reduce_sum(x_tmp,axis=2)/tf.reshape(N_k,[batch_size,k,1])\n          sigma=tf.sqrt(sigma)\n              \n        weighted_prediction=tf.multiply(caps_predicted,tf.reshape(R,[batch_size,n,k,1,1]))\n        weighted_sum = tf.reduce_sum(weighted_prediction, axis=1, keepdims=True)\n        v=squash(weighted_sum, axis=-2)\n        v = tf.squeeze(v, axis=[1,4])\n        return v\n\n    def compute_output_signature(self,input_shape):\n      return tf.TensorSpec(shape=[input_shape[0],self.caps_n,self.caps_dim],dtype=tf.float64)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:38:05.982515Z","iopub.execute_input":"2022-11-05T10:38:05.982962Z","iopub.status.idle":"2022-11-05T10:38:06.006818Z","shell.execute_reply.started":"2022-11-05T10:38:05.982928Z","shell.execute_reply":"2022-11-05T10:38:06.005782Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"c1=tf.keras.layers.Conv2D(16,kernel_size=5,strides=1,padding='valid',activation='relu')\nc2=tf.keras.layers.Conv2D(32,kernel_size=9,strides=1,padding='valid',activation='relu')\nbn1=tf.keras.layers.BatchNormalization()\nbn2=tf.keras.layers.BatchNormalization()\nlast=Capsule(10,16)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:00:13.754860Z","iopub.execute_input":"2022-11-05T11:00:13.755231Z","iopub.status.idle":"2022-11-05T11:00:13.766814Z","shell.execute_reply.started":"2022-11-05T11:00:13.755199Z","shell.execute_reply":"2022-11-05T11:00:13.765879Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model_input = keras.Input(shape=(28,28,1), batch_size=32)\nx=c1(model_input)\nx=bn1(x,training=True)\nx=c2(x)\nx=bn2(x,training=True)\nx=tf.reshape(x,[-1,16*32,16])\nx=last(x)\nx=tf.cast(x,tf.float32)\nx=safe_norm(x, axis=2)\nmodel_output = x\n","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:00:16.474209Z","iopub.execute_input":"2022-11-05T11:00:16.474561Z","iopub.status.idle":"2022-11-05T11:00:16.736175Z","shell.execute_reply.started":"2022-11-05T11:00:16.474531Z","shell.execute_reply":"2022-11-05T11:00:16.735121Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = keras.Model(model_input, model_output, name=\"encoder\")","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:00:20.184621Z","iopub.execute_input":"2022-11-05T11:00:20.184999Z","iopub.status.idle":"2022-11-05T11:00:20.193959Z","shell.execute_reply.started":"2022-11-05T11:00:20.184970Z","shell.execute_reply":"2022-11-05T11:00:20.192870Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"adam = tf.keras.optimizers.Adam(learning_rate=0.0001) \nmodel.compile(loss=margin_loss,\n              optimizer=adam,\n              metrics=tf.keras.metrics.CategoricalAccuracy())\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:00:30.481751Z","iopub.execute_input":"2022-11-05T11:00:30.482144Z","iopub.status.idle":"2022-11-05T11:00:30.498581Z","shell.execute_reply.started":"2022-11-05T11:00:30.482112Z","shell.execute_reply":"2022-11-05T11:00:30.497345Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Model: \"encoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(32, 28, 28, 1)]         0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (32, 24, 24, 16)          416       \n_________________________________________________________________\nbatch_normalization_6 (Batch (32, 24, 24, 16)          64        \n_________________________________________________________________\nconv2d_7 (Conv2D)            (32, 16, 16, 32)          41504     \n_________________________________________________________________\nbatch_normalization_7 (Batch (32, 16, 16, 32)          128       \n_________________________________________________________________\ntf.reshape_3 (TFOpLambda)    (32, 512, 16)             0         \n_________________________________________________________________\ncapsule_3 (Capsule)          (32, 10, 16)              1310720   \n_________________________________________________________________\ntf.cast_3 (TFOpLambda)       (32, 10, 16)              0         \n_________________________________________________________________\ntf.math.square_3 (TFOpLambda (32, 10, 16)              0         \n_________________________________________________________________\ntf.math.reduce_sum_3 (TFOpLa (32, 10)                  0         \n_________________________________________________________________\ntf.__operators__.add_3 (TFOp (32, 10)                  0         \n_________________________________________________________________\ntf.math.sqrt_3 (TFOpLambda)  (32, 10)                  0         \n=================================================================\nTotal params: 1,352,832\nTrainable params: 1,352,736\nNon-trainable params: 96\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# data loading in appropriate formate\n\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# Add a channels dimension\nx_train = x_train[..., tf.newaxis].astype(\"float32\")\nx_test = x_test[..., tf.newaxis].astype(\"float32\")\n\ny_train=tf.keras.utils.to_categorical(y_train)\ny_test=tf.keras.utils.to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:40:32.689219Z","iopub.execute_input":"2022-11-05T10:40:32.689578Z","iopub.status.idle":"2022-11-05T10:40:33.180418Z","shell.execute_reply.started":"2022-11-05T10:40:32.689546Z","shell.execute_reply":"2022-11-05T10:40:33.179364Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train, y_train, batch_size=32,epochs=10,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:00:37.416764Z","iopub.execute_input":"2022-11-05T11:00:37.417173Z","iopub.status.idle":"2022-11-05T11:08:30.863779Z","shell.execute_reply.started":"2022-11-05T11:00:37.417139Z","shell.execute_reply":"2022-11-05T11:08:30.862163Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1500/1500 [==============================] - 90s 58ms/step - loss: 0.1700 - categorical_accuracy: 0.8379 - val_loss: 0.1660 - val_categorical_accuracy: 0.8522\nEpoch 2/10\n1500/1500 [==============================] - 87s 58ms/step - loss: 0.1057 - categorical_accuracy: 0.9217 - val_loss: 0.1425 - val_categorical_accuracy: 0.8808\nEpoch 3/10\n1500/1500 [==============================] - 87s 58ms/step - loss: 0.0902 - categorical_accuracy: 0.9359 - val_loss: 0.1377 - val_categorical_accuracy: 0.8863\nEpoch 4/10\n1500/1500 [==============================] - 87s 58ms/step - loss: 0.0807 - categorical_accuracy: 0.9441 - val_loss: 0.1307 - val_categorical_accuracy: 0.8904\nEpoch 5/10\n1500/1500 [==============================] - 88s 59ms/step - loss: 0.0734 - categorical_accuracy: 0.9515 - val_loss: 0.1204 - val_categorical_accuracy: 0.9062\nEpoch 6/10\n 658/1500 [============>.................] - ETA: 43s - loss: 0.0677 - categorical_accuracy: 0.9557","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1444935802.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"#loss=margin_loss","metadata":{},"execution_count":null,"outputs":[]}]}