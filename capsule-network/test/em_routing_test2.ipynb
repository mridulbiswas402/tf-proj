{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "-DCbvfO3CvPM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp"
      ],
      "metadata": {
        "id": "9qRNpO1Wx61L"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "iEc0gm13CvME"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import random"
      ],
      "metadata": {
        "id": "VsKVCiHmyQdU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "YJpp1ZU8CvI7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = tf.math.reduce_sum(tf.math.square(x), axis, keepdims=True) + keras.backend.epsilon()\n",
        "    scale = tf.math.sqrt(s_squared_norm) / (1 + s_squared_norm)\n",
        "    return scale * x\n",
        "\n",
        "@tf.function\n",
        "def margin_loss(y_true, y_pred):\n",
        "    lamb, margin = 0.5, 0.1\n",
        "    return tf.math.reduce_sum((y_true * tf.math.square(tf.nn.relu(1 - margin - y_pred)) + lamb * (\n",
        "        1 - y_true) * tf.math.square(tf.nn.relu(y_pred - margin))), axis=-1)\n",
        "\n",
        "#@tf.function\n",
        "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False):\n",
        "        squared_norm = tf.reduce_sum(tf.square(s),axis=axis,keepdims=keep_dims)\n",
        "        return tf.sqrt(squared_norm + epsilon)"
      ],
      "metadata": {
        "id": "ppnv09zACvGE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Capsule(keras.layers.Layer):\n",
        "   \n",
        "\n",
        "    def __init__(self,\n",
        "                 num_capsule,\n",
        "                 dim_capsule,\n",
        "                 routings=3,\n",
        "                 **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.caps_n = num_capsule\n",
        "        self.caps_dim = dim_capsule\n",
        "        self.r = routings\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "        'num_capsule':  self.caps_n,\n",
        "        'dim_capsule' : self.caps_dim,\n",
        "        'routings':  self.r,      \n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        batch_size = input_shape[0]\n",
        "        n=input_shape[1]\n",
        "        k=self.caps_n\n",
        "        d=self.caps_dim\n",
        "\n",
        "        self.W = self.add_weight(name='W',\n",
        "                    shape=[1, input_shape[1], self.caps_n, self.caps_dim, input_shape[-1]],\n",
        "                    dtype=tf.float64,\n",
        "                    initializer='glorot_uniform',\n",
        "                    trainable=True)\n",
        "        \n",
        "        #initialization step.\n",
        "        init_mu = random.rand(batch_size,k, d)*20 - 10\n",
        "        self.mu = init_mu #initializing mean.\n",
        "\n",
        "        init_sigma = np.zeros((k, d, d))\n",
        "        for i in range(k):\n",
        "            init_sigma[i] = np.eye(d)\n",
        "        sigma = init_sigma\n",
        "        sigma=tf.expand_dims(sigma,axis=0)\n",
        "        self.sigma=tf.tile(sigma,[batch_size,1,1,1]) # initializing cov matrix.\n",
        "\n",
        "        init_pi = np.ones(k)/k\n",
        "        pi = init_pi\n",
        "        pi=tf.expand_dims(pi,axis=0)\n",
        "        self.pi=tf.tile(pi,[batch_size,1])\n",
        "\n",
        "        R=np.zeros(shape=(n,k))\n",
        "        R=tf.expand_dims(R,axis=0)\n",
        "        self.R=tf.tile(R,[batch_size,1,1]) # coupling coefficient.\n",
        "        \n",
        "    def call(self, input_tensor):\n",
        "        assert input_tensor.shape[2]==self.caps_dim\n",
        "        input_tensor=tf.cast(input_tensor,dtype=tf.float64)\n",
        "        assert input_tensor.dtype==tf.float64\n",
        "        batch_size = input_tensor.shape[0]\n",
        "        n=input_tensor.shape[1]\n",
        "        k=self.caps_n\n",
        "        d=self.caps_dim\n",
        "        \n",
        "        W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1]) # replicating the weights for parallel processing of a batch.\n",
        "        \"\"\" W_tiled.shape=[batch_size,caps_n(i-1),caps_n(i),caps_dim(i),caps_dim(i-1)] \"\"\"\n",
        "\n",
        "        caps_output_expanded = tf.expand_dims(input_tensor, -1) # converting last dim to a column vector.\n",
        "        \"\"\" the above step change the input shape from \n",
        "            [batch_size,caps_n(i-1),caps_dim(i-1)] --> [batch_size,caps_n(i-1),caps_dim(i-1),1]\"\"\"\n",
        "\n",
        "        caps_output_tile = tf.expand_dims(caps_output_expanded, 2)\n",
        "        \"\"\" the above step change the input shape from \n",
        "            [batch_size,caps_n(i-1),caps_dim(i-1),1] --> [batch_size,caps_n(i-1),1,caps_dim(i-1),1]\"\"\"\n",
        "\n",
        "        caps_output_tiled = tf.tile(caps_output_tile, [1, 1, self.caps_n, 1, 1]) # replicating the input capsule vector for every output capsule.\n",
        "        \"\"\" i.e [batch_size,caps_n(i-1),1,caps_dim(i-1),1] --> [batch_size,caps_n(i-1),caps_n(i),1,caps_dim(i-1),1]\"\"\"\n",
        "\n",
        "        caps_predicted = tf.matmul(W_tiled, caps_output_tiled) # this is performing element wise tf.matmul() operation.\n",
        "        \"\"\" caps_predicted.shape = [1,caps_n(i-1),caps_n(i),caps_dim(i),1]\"\"\"\n",
        "\n",
        "        \"\"\" dynamic routing \"\"\"\n",
        "        \"\"\"#initialization step.\n",
        "        init_mu = random.rand(batch_size,k, d)*20 - 10\n",
        "        mu = init_mu #initializing mean.\n",
        "\n",
        "        init_sigma = np.zeros((k, d, d))\n",
        "        for i in range(k):\n",
        "            init_sigma[i] = np.eye(d)\n",
        "        sigma = init_sigma\n",
        "        sigma=tf.expand_dims(sigma,axis=0)\n",
        "        sigma=tf.tile(sigma,[batch_size,1,1,1]) # initializing cov matrix.\n",
        "\n",
        "        init_pi = np.ones(k)/k\n",
        "        pi = init_pi\n",
        "        pi=tf.expand_dims(pi,axis=0)\n",
        "        pi=tf.tile(pi,[batch_size,1])\n",
        "\n",
        "        R=np.zeros(shape=(n,k))\n",
        "        R=tf.expand_dims(R,axis=0)\n",
        "        R=tf.tile(R,[batch_size,1,1]) # coupling coefficient.\"\"\"\n",
        "\n",
        "        pi=tf.Variable(self.pi,dtype=tf.float64)\n",
        "        mu=tf.Variable(self.mu,dtype=tf.float64)\n",
        "        sigma=tf.Variable(self.sigma,dtype=tf.float64)\n",
        "        R=tf.Variable(self.R,dtype=tf.float64)\n",
        "\n",
        "        #print(mu.shape,pi.shape,sigma.shape,R.shape)\n",
        "\n",
        "        N=np.zeros((batch_size,n))\n",
        "        N=tf.Variable(N,dtype=tf.float64)\n",
        "\n",
        "        r=self.r\n",
        "        while(r):\n",
        "          r=r-1\n",
        "          # E-step.\n",
        "          for i in range(k):\n",
        "              for b in range(batch_size):\n",
        "                  tmp = tfp.distributions.MultivariateNormalFullCovariance(loc=mu[b][i],\n",
        "                                                                        covariance_matrix=sigma[b][i]).prob(z[b])\n",
        "                  N[b].assign(tmp)\n",
        "              R[:,:,i].assign(tf.expand_dims(pi[:,i],axis=1)*N)\n",
        "          R.assign(R/tf.reduce_sum(R,axis=2, keepdims=True))\n",
        "\n",
        "          # M-step\n",
        "          N_k=tf.reduce_sum(R,axis=1)\n",
        "          pi=N_k/n\n",
        "          mu=tf.matmul(tf.transpose(R,perm=[0,2,1]),z)\n",
        "          mu=mu/N_k[:,:,None]\n",
        "\n",
        "          for i in range(k):\n",
        "              tmp=z-tf.expand_dims(mu[:,i,:],axis=1)\n",
        "              tmp=tf.expand_dims(tmp,axis=-1)\n",
        "              tmp_T=tf.transpose(tmp,perm=[0,1,3,2])\n",
        "              res=tf.matmul(tmp,tmp_T)\n",
        "              res=tf.multiply(tf.reshape(R[:,:,i],[batch_size,n,1,1]),res)\n",
        "              res=tf.reduce_sum(res,axis=1)/tf.reshape(N_k[:,i],[batch_size,1,1])\n",
        "              sigma[:,i].assign(res)\n",
        "              \n",
        "        weighted_prediction=tf.multiply(caps_predicted,tf.reshape(R,[batch_size,n,k,1,1]))\n",
        "        weighted_sum = tf.reduce_sum(weighted_prediction, axis=1, keepdims=True)\n",
        "        v=squash(weighted_sum, axis=-2)\n",
        "        v = tf.squeeze(v, axis=[1,4])\n",
        "        return v"
      ],
      "metadata": {
        "id": "FWhXR-7ZTka9"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c1=tf.keras.layers.Conv2D(16,kernel_size=3,strides=1,padding='valid',activation='relu')\n",
        "c2=tf.keras.layers.Conv2D(32,kernel_size=5,strides=2,padding='valid',activation='relu')"
      ],
      "metadata": {
        "id": "JYtOCQh1wlth"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Capsule(32,8)"
      ],
      "metadata": {
        "id": "cFYOxjrPwxEF"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading in appropriate formate\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float64\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float64\")"
      ],
      "metadata": {
        "id": "EcMotGZn93Qx"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=x_train[:32]"
      ],
      "metadata": {
        "id": "Pdc7M_auw450"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z=c2(c1(X))"
      ],
      "metadata": {
        "id": "2JuMbjmdw8sZ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1lrvVcWw_ex",
        "outputId": "d8fd80c9-e715-41ae-a51f-7e58467ef5e1"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 11, 11, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=tf.reshape(z,(-1,484,8))"
      ],
      "metadata": {
        "id": "e139uiQSxAzZ"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z=tf.cast(z,dtype=tf.float64)"
      ],
      "metadata": {
        "id": "Dx-llocDxJqI"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeUWCx7t0VQZ",
        "outputId": "09a81cf3-9f74-4a4f-aff2-cf4ef76633b0"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 484, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bggm-F-0xK74",
        "outputId": "2b7ca44b-8be7-409b-8b30-961bd59a633f"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 32, 8), dtype=float64, numpy=\n",
              "array([[[ 2.60525010e-39, -1.10744637e-39,  5.17747581e-39, ...,\n",
              "         -5.12111835e-39,  1.47361385e-39,  4.20327545e-39],\n",
              "        [ 3.77290147e-15,  3.03763049e-15, -3.15913735e-15, ...,\n",
              "         -2.56150151e-15, -2.39209760e-16,  4.92679079e-16],\n",
              "        [-3.09397448e-38,  3.19553504e-38, -3.38924579e-38, ...,\n",
              "         -3.66954949e-38,  1.93367930e-38,  9.97688436e-40],\n",
              "        ...,\n",
              "        [-8.91536481e-24, -1.25219929e-23, -2.38204248e-23, ...,\n",
              "          4.82921722e-23,  5.76069843e-24, -3.93484628e-23],\n",
              "        [-2.67297426e-44, -1.23796962e-44, -2.22491837e-44, ...,\n",
              "          1.48530721e-44,  1.59411309e-44, -1.61663921e-44],\n",
              "        [ 2.72908273e-14,  1.09342643e-13,  1.01090134e-13, ...,\n",
              "          5.03776621e-14, -1.04412165e-13, -6.17895605e-14]],\n",
              "\n",
              "       [[-1.43309715e-12, -5.12576378e-12,  1.47106051e-12, ...,\n",
              "         -2.68715109e-12, -7.38666075e-13,  3.31803853e-12],\n",
              "        [ 4.81911919e-19,  2.08407644e-19, -1.21663457e-18, ...,\n",
              "          1.05587814e-18, -4.59119999e-19, -1.42416407e-18],\n",
              "        [ 1.41621524e-76, -3.00042791e-77,  7.30869061e-77, ...,\n",
              "          4.43836955e-77, -7.09501370e-77,  5.06233249e-77],\n",
              "        ...,\n",
              "        [-1.19950557e-04,  3.16817718e-04,  1.92428598e-05, ...,\n",
              "          8.97101573e-05, -9.18759317e-05,  4.66203748e-04],\n",
              "        [ 4.56942567e-45,  1.08823388e-44, -6.75540158e-45, ...,\n",
              "         -1.08131247e-44, -5.49061563e-45, -4.05015708e-46],\n",
              "        [ 4.18947375e-06,  2.27405878e-06, -5.69457641e-06, ...,\n",
              "          4.42366298e-06, -2.41496887e-06,  5.69982713e-06]],\n",
              "\n",
              "       [[-1.29344156e-45,  1.70598736e-46, -1.18044418e-45, ...,\n",
              "          2.37529637e-46, -6.40212389e-46, -3.68960638e-46],\n",
              "        [ 3.30151403e-34,  7.67056280e-34,  1.30968959e-33, ...,\n",
              "         -5.97827392e-35,  1.56077297e-34,  4.53865637e-35],\n",
              "        [ 8.50259171e-49,  1.22690248e-48,  3.16931393e-48, ...,\n",
              "         -1.71873804e-48, -3.82428029e-49, -4.72156162e-48],\n",
              "        ...,\n",
              "        [ 8.44558922e-06,  1.16434857e-05, -1.76523544e-05, ...,\n",
              "         -3.05703071e-06, -4.06536605e-06, -5.23229197e-06],\n",
              "        [ 4.47179019e-75,  4.87911450e-75, -4.46237049e-75, ...,\n",
              "         -2.69693344e-75, -1.46597693e-75,  3.85097989e-75],\n",
              "        [ 7.38546025e-45,  1.13782841e-44, -6.21787153e-45, ...,\n",
              "         -1.21320335e-46, -1.51660951e-45,  1.77295133e-45]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 2.86624910e-42,  9.34690497e-43,  8.19413265e-43, ...,\n",
              "         -4.44439169e-42, -2.28543490e-42,  1.54188843e-42],\n",
              "        [ 4.19866253e-53, -1.92215309e-52,  4.91144206e-52, ...,\n",
              "          1.96676751e-52,  6.48269999e-52,  7.58948923e-52],\n",
              "        [ 7.01256890e-07, -1.57991588e-06, -6.43229940e-06, ...,\n",
              "         -4.48597100e-06,  2.60935432e-06, -4.74403011e-06],\n",
              "        ...,\n",
              "        [ 4.82939297e-21,  2.62945997e-20, -2.91757234e-20, ...,\n",
              "         -1.01940955e-20, -3.05630599e-20, -5.33792365e-21],\n",
              "        [ 9.40289497e-46,  2.06780778e-46,  2.41929571e-46, ...,\n",
              "          1.34095123e-47, -4.71067863e-47,  7.19547983e-46],\n",
              "        [ 8.16325462e-10, -1.19943577e-09,  1.98951764e-09, ...,\n",
              "         -1.80546331e-09,  1.82975610e-10,  8.32371646e-10]],\n",
              "\n",
              "       [[ 2.58215136e-50, -4.54242524e-50,  6.41601653e-50, ...,\n",
              "         -2.83716065e-50,  2.96307318e-50,  3.78960973e-50],\n",
              "        [-4.48738866e-24, -3.82670958e-24,  5.81025074e-25, ...,\n",
              "          5.16882887e-25,  2.39750991e-25,  5.42634347e-24],\n",
              "        [ 3.84663792e-06,  3.06392423e-06, -3.09405924e-06, ...,\n",
              "         -5.40238516e-06,  6.43128126e-07, -4.16746965e-06],\n",
              "        ...,\n",
              "        [ 2.08000018e-06, -1.68114306e-06,  1.29798521e-06, ...,\n",
              "         -6.12920909e-07, -1.53929256e-06, -1.33617796e-06],\n",
              "        [ 8.39600780e-36, -5.12797197e-36, -1.07655417e-35, ...,\n",
              "         -4.88638021e-36,  7.50193666e-36,  2.62391391e-36],\n",
              "        [ 5.38368717e-28, -3.32733803e-28, -3.55155984e-29, ...,\n",
              "         -1.30014576e-27,  1.29962096e-27,  7.98152103e-28]],\n",
              "\n",
              "       [[-2.18392242e-40,  7.45110297e-40, -9.36428577e-40, ...,\n",
              "          5.03614194e-40,  6.19913551e-40, -5.53877587e-40],\n",
              "        [ 1.03227034e-35, -2.95489828e-36,  2.79142125e-35, ...,\n",
              "          5.73396317e-36,  1.17180354e-35,  5.68161113e-36],\n",
              "        [ 6.18455737e-59, -1.09461696e-58, -7.69799708e-59, ...,\n",
              "          1.63774506e-59,  4.86042273e-60,  7.40998800e-59],\n",
              "        ...,\n",
              "        [ 3.26780978e-22,  1.69199818e-22, -1.78150866e-22, ...,\n",
              "          5.91231386e-23, -4.23712327e-23, -1.64479886e-22],\n",
              "        [-1.27626887e-30,  4.39127225e-31, -1.90468457e-31, ...,\n",
              "         -2.54161593e-31, -1.61384943e-30,  2.06094443e-30],\n",
              "        [ 3.95334174e-30, -4.57512934e-30, -5.09485737e-30, ...,\n",
              "          1.13121169e-29,  6.34829952e-30, -1.54475629e-30]]])>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4U_8gALDxOce"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}