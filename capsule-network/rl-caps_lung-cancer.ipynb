{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:08.550864Z","iopub.status.busy":"2022-11-24T08:09:08.550457Z","iopub.status.idle":"2022-11-24T08:09:13.981141Z","shell.execute_reply":"2022-11-24T08:09:13.980142Z","shell.execute_reply.started":"2022-11-24T08:09:08.550782Z"},"trusted":true},"outputs":[],"source":["import os                       # for working with files\n","import numpy as np              # for numerical computationss\n","import pandas as pd             # for working with dataframes\n","import seaborn as sns\n","import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n","from PIL import Image           # for checking images\n","import tensorflow as tf \n","from  tensorflow import keras\n","import itertools\n","from sklearn.metrics import precision_score, accuracy_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:13.983696Z","iopub.status.busy":"2022-11-24T08:09:13.983017Z","iopub.status.idle":"2022-11-24T08:09:13.991701Z","shell.execute_reply":"2022-11-24T08:09:13.990840Z","shell.execute_reply.started":"2022-11-24T08:09:13.983659Z"},"trusted":true},"outputs":[],"source":["lung_dir = \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets\"\n","lungs = os.listdir(lung_dir)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:13.993480Z","iopub.status.busy":"2022-11-24T08:09:13.993076Z","iopub.status.idle":"2022-11-24T08:09:14.020678Z","shell.execute_reply":"2022-11-24T08:09:14.019569Z","shell.execute_reply.started":"2022-11-24T08:09:13.993445Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['lung_aca', 'lung_scc', 'lung_n']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["lungs"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:14.023801Z","iopub.status.busy":"2022-11-24T08:09:14.023461Z","iopub.status.idle":"2022-11-24T08:09:14.427703Z","shell.execute_reply":"2022-11-24T08:09:14.426742Z","shell.execute_reply.started":"2022-11-24T08:09:14.023768Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["lung_aca : 5000\n","lung_scc : 5000\n","lung_n : 5000\n"]}],"source":["for i in lungs:\n","    print(\"%s : %d\"%(i,len(os.listdir(lung_dir+\"/\"+i))))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:14.429483Z","iopub.status.busy":"2022-11-24T08:09:14.429158Z","iopub.status.idle":"2022-11-24T08:09:25.803028Z","shell.execute_reply":"2022-11-24T08:09:25.802045Z","shell.execute_reply.started":"2022-11-24T08:09:14.429450Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 15000 files belonging to 3 classes.\n","Using 12000 files for training.\n"]},{"name":"stderr","output_type":"stream","text":["2022-11-24 08:09:20.117289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-24 08:09:20.213447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-24 08:09:20.214236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-24 08:09:20.217332: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-11-24 08:09:20.217630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-24 08:09:20.218373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-24 08:09:20.219006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-24 08:09:22.473664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-24 08:09:22.474575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-24 08:09:22.475238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-24 08:09:22.475925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]},{"name":"stdout","output_type":"stream","text":["Found 15000 files belonging to 3 classes.\n","Using 3000 files for validation.\n"]}],"source":["train_dataset = tf.keras.utils.image_dataset_from_directory(\n","    lung_dir,\n","    labels='inferred',\n","    label_mode='categorical',\n","    class_names=None,\n","    color_mode='rgb',\n","    batch_size=64,\n","    image_size=(256, 256),\n","    shuffle=True,\n","    seed=47,\n","    validation_split=0.2,\n","    subset=\"training\"\n",")\n","\n","val_dataset = tf.keras.utils.image_dataset_from_directory(\n","    lung_dir,\n","    labels='inferred',\n","    label_mode='categorical',\n","    class_names=None,\n","    color_mode='rgb',\n","    batch_size=64,\n","    image_size=(256, 256),\n","    shuffle=True,\n","    seed=47,\n","    validation_split=0.2,\n","    subset=\"validation\"\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:25.804846Z","iopub.status.busy":"2022-11-24T08:09:25.804521Z","iopub.status.idle":"2022-11-24T08:09:25.811177Z","shell.execute_reply":"2022-11-24T08:09:25.810057Z","shell.execute_reply.started":"2022-11-24T08:09:25.804811Z"},"trusted":true},"outputs":[],"source":["#optimization parameter setting.\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:25.813322Z","iopub.status.busy":"2022-11-24T08:09:25.812711Z","iopub.status.idle":"2022-11-24T08:09:25.826063Z","shell.execute_reply":"2022-11-24T08:09:25.825088Z","shell.execute_reply.started":"2022-11-24T08:09:25.813287Z"},"trusted":true},"outputs":[],"source":["@tf.function\n","def squash(x, axis=-1):\n","    s_squared_norm = tf.math.reduce_sum(tf.math.square(x), axis, keepdims=True) + keras.backend.epsilon()\n","    scale = tf.math.sqrt(s_squared_norm) / (1 + s_squared_norm)\n","    return scale * x\n","\n","@tf.function\n","def margin_loss(y_true, y_pred):\n","    lamb, margin = 0.5, 0.1\n","    return tf.math.reduce_sum((y_true * tf.math.square(tf.nn.relu(1 - margin - y_pred)) + lamb * (\n","        1 - y_true) * tf.math.square(tf.nn.relu(y_pred - margin))), axis=-1)\n","\n","#@tf.function\n","def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False):\n","        squared_norm = tf.reduce_sum(tf.square(s),axis=axis,keepdims=keep_dims)\n","        return tf.sqrt(squared_norm + epsilon)\n","    "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:25.828780Z","iopub.status.busy":"2022-11-24T08:09:25.828335Z","iopub.status.idle":"2022-11-24T08:09:25.842674Z","shell.execute_reply":"2022-11-24T08:09:25.841674Z","shell.execute_reply.started":"2022-11-24T08:09:25.828725Z"},"trusted":true},"outputs":[],"source":["class Capsule(keras.layers.Layer):\n","   \n","\n","    def __init__(self,\n","                 num_capsule,\n","                 dim_capsule,\n","                 **kwargs):\n","        super(Capsule, self).__init__(**kwargs)\n","        self.caps_n = num_capsule\n","        self.caps_dim = dim_capsule\n","\n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","        'num_capsule':  self.caps_n,\n","        'dim_capsule' : self.caps_dim,    \n","        })\n","        return config\n","\n","    def build(self, input_shape):\n","\n","        self.W = self.add_weight(name='W',\n","                    shape=[1, input_shape[1], self.caps_n, self.caps_dim, input_shape[-1]],\n","                    dtype=tf.float32,\n","                    initializer='glorot_uniform',\n","                    trainable=True)\n","        \n","        self.R = self.add_weight(name='R',\n","                    shape=[1, input_shape[1], self.caps_n],\n","                    dtype=tf.float32,\n","                    initializer='glorot_uniform',\n","                    trainable=True)\n","        \n","        \n","    def call(self, input_tensor):\n","        batch_size = input_tensor.shape[0]\n","        n=input_tensor.shape[1]\n","        k=self.caps_n\n","        \n","        W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1])\n","        \n","        R_tiled = tf.tile(self.R,[batch_size,1,1])\n","        R_tiled = tf.nn.softmax(R_tiled,axis=1)\n","\n","        caps_output_expanded = tf.expand_dims(input_tensor, -1) # converting last dim to a column vector.\n","        caps_output_tile = tf.expand_dims(caps_output_expanded, 2)\n","        caps_output_tiled = tf.tile(caps_output_tile, [1, 1, self.caps_n, 1, 1]) # replicating the input capsule vector for every output capsule.\n","        caps_predicted = tf.matmul(W_tiled, caps_output_tiled) # this is performing element wise tf.matmul() operation.       \n","        weighted_prediction=tf.multiply(caps_predicted,tf.reshape(R_tiled,[batch_size,n,k,1,1]))\n","        weighted_sum = tf.reduce_sum(weighted_prediction, axis=1, keepdims=True)\n","        v=squash(weighted_sum, axis=-2)\n","        v = tf.squeeze(v, axis=[1,4])\n","        return v"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:25.844507Z","iopub.status.busy":"2022-11-24T08:09:25.844171Z","iopub.status.idle":"2022-11-24T08:09:25.880255Z","shell.execute_reply":"2022-11-24T08:09:25.879416Z","shell.execute_reply.started":"2022-11-24T08:09:25.844469Z"},"trusted":true},"outputs":[],"source":["c1=tf.keras.layers.Conv2D(8,kernel_size=5,strides=2,padding='valid',activation='relu')\n","c2=tf.keras.layers.Conv2D(8,kernel_size=9,strides=2,padding='valid',activation='relu')\n","c3=tf.keras.layers.Conv2D(8,kernel_size=9,strides=2,padding='valid',activation='relu')\n","c4=tf.keras.layers.Conv2D(8,kernel_size=11,strides=1,padding='valid',activation='relu')\n","#dc1=tf.keras.layers.DepthwiseConv2D(kernel_size=9,strides=(1, 1),padding='valid',activation='relu')\n","last=Capsule(3,8)\n","bn1=tf.keras.layers.BatchNormalization()\n","bn2=tf.keras.layers.BatchNormalization()\n","bn3=tf.keras.layers.BatchNormalization()\n","bn4=tf.keras.layers.BatchNormalization()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:25.883831Z","iopub.status.busy":"2022-11-24T08:09:25.883547Z","iopub.status.idle":"2022-11-24T08:09:25.890349Z","shell.execute_reply":"2022-11-24T08:09:25.889103Z","shell.execute_reply.started":"2022-11-24T08:09:25.883808Z"},"trusted":true},"outputs":[],"source":["X=keras.Input((256,256,3),batch_size=64)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:25.892469Z","iopub.status.busy":"2022-11-24T08:09:25.892132Z","iopub.status.idle":"2022-11-24T08:09:25.943771Z","shell.execute_reply":"2022-11-24T08:09:25.942860Z","shell.execute_reply.started":"2022-11-24T08:09:25.892429Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<KerasTensor: shape=(64, 16, 16, 8) dtype=float32 (created by layer 'conv2d_3')>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["c4(c3(c2(c1(X))))"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:25.945334Z","iopub.status.busy":"2022-11-24T08:09:25.945028Z","iopub.status.idle":"2022-11-24T08:09:26.220574Z","shell.execute_reply":"2022-11-24T08:09:26.219692Z","shell.execute_reply.started":"2022-11-24T08:09:25.945304Z"},"trusted":true},"outputs":[],"source":["model_input = keras.Input(shape=(256, 256, 3), batch_size=64)\n","x=c1(model_input)\n","x=bn1(x,training=True)\n","x=c2(x)\n","x=bn2(x,training=True)\n","x=c3(x)\n","x=bn3(x,training=True)\n","x=c4(x)\n","x=bn4(x,training=True)\n","#x=dc1(x)\n","x=tf.reshape(x,[-1,16*16,8])\n","x=last(x)\n","x=safe_norm(x, axis=2)\n","model_output = x"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:26.222361Z","iopub.status.busy":"2022-11-24T08:09:26.222051Z","iopub.status.idle":"2022-11-24T08:09:26.231213Z","shell.execute_reply":"2022-11-24T08:09:26.230047Z","shell.execute_reply.started":"2022-11-24T08:09:26.222328Z"},"trusted":true},"outputs":[],"source":["model = keras.Model(model_input, model_output)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:26.233302Z","iopub.status.busy":"2022-11-24T08:09:26.232770Z","iopub.status.idle":"2022-11-24T08:09:26.265943Z","shell.execute_reply":"2022-11-24T08:09:26.263570Z","shell.execute_reply.started":"2022-11-24T08:09:26.233268Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(64, 256, 256, 3)]       0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (64, 126, 126, 8)         608       \n","_________________________________________________________________\n","batch_normalization (BatchNo (64, 126, 126, 8)         32        \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (64, 59, 59, 8)           5192      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (64, 59, 59, 8)           32        \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (64, 26, 26, 8)           5192      \n","_________________________________________________________________\n","batch_normalization_2 (Batch (64, 26, 26, 8)           32        \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (64, 16, 16, 8)           7752      \n","_________________________________________________________________\n","batch_normalization_3 (Batch (64, 16, 16, 8)           32        \n","_________________________________________________________________\n","tf.reshape (TFOpLambda)      (64, 256, 8)              0         \n","_________________________________________________________________\n","capsule (Capsule)            (64, 3, 8)                49920     \n","_________________________________________________________________\n","tf.math.square (TFOpLambda)  (64, 3, 8)                0         \n","_________________________________________________________________\n","tf.math.reduce_sum (TFOpLamb (64, 3)                   0         \n","_________________________________________________________________\n","tf.__operators__.add (TFOpLa (64, 3)                   0         \n","_________________________________________________________________\n","tf.math.sqrt (TFOpLambda)    (64, 3)                   0         \n","=================================================================\n","Total params: 68,792\n","Trainable params: 68,728\n","Non-trainable params: 64\n","_________________________________________________________________\n"]}],"source":["adam = tf.keras.optimizers.Adam(learning_rate=0.0001) \n","\n","model.compile(loss=margin_loss, optimizer=adam, metrics=tf.keras.metrics.CategoricalAccuracy())\n","model.summary()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:09:26.268127Z","iopub.status.busy":"2022-11-24T08:09:26.267378Z","iopub.status.idle":"2022-11-24T08:09:26.288240Z","shell.execute_reply":"2022-11-24T08:09:26.284737Z","shell.execute_reply.started":"2022-11-24T08:09:26.268083Z"},"trusted":true},"outputs":[],"source":["\"\"\"customize training loop.\"\"\"\n","\n","# Instantiate an optimizer to train the model.\n","base_learning_rate = 0.0001\n","optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n","# Instantiate a loss function.\n","loss_fn = margin_loss\n","\n","# Prepare the metrics.\n","train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n","val_acc_metric = tf.keras.metrics.CategoricalAccuracy()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T08:37:28.938036Z","iopub.status.busy":"2022-11-24T08:37:28.937661Z","iopub.status.idle":"2022-11-24T09:03:46.743574Z","shell.execute_reply":"2022-11-24T09:03:46.742563Z","shell.execute_reply.started":"2022-11-24T08:37:28.938005Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","epoch 1/30\n","188/188 [==============================] - 52s 269ms/step - train_acc: 0.8721 - val_acc: 0.8773\n","\n","epoch 2/30\n","188/188 [==============================] - 51s 262ms/step - train_acc: 0.8746 - val_acc: 0.8660\n","\n","epoch 3/30\n","188/188 [==============================] - 51s 261ms/step - train_acc: 0.8813 - val_acc: 0.8777\n","\n","epoch 4/30\n","188/188 [==============================] - 49s 252ms/step - train_acc: 0.8820 - val_acc: 0.8867\n","\n","epoch 5/30\n","188/188 [==============================] - 51s 263ms/step - train_acc: 0.8856 - val_acc: 0.8830\n","\n","epoch 6/30\n","188/188 [==============================] - 51s 265ms/step - train_acc: 0.8905 - val_acc: 0.8887\n","\n","epoch 7/30\n","188/188 [==============================] - 92s 483ms/step - train_acc: 0.8949 - val_acc: 0.8957\n","\n","epoch 8/30\n","188/188 [==============================] - 51s 262ms/step - train_acc: 0.8991 - val_acc: 0.8923\n","\n","epoch 9/30\n","188/188 [==============================] - 52s 269ms/step - train_acc: 0.8997 - val_acc: 0.9080\n","\n","epoch 10/30\n","188/188 [==============================] - 51s 264ms/step - train_acc: 0.9036 - val_acc: 0.9020\n","\n","epoch 11/30\n","188/188 [==============================] - 51s 265ms/step - train_acc: 0.9102 - val_acc: 0.9117\n","\n","epoch 12/30\n","188/188 [==============================] - 52s 270ms/step - train_acc: 0.9054 - val_acc: 0.9120\n","\n","epoch 13/30\n","188/188 [==============================] - 51s 262ms/step - train_acc: 0.9147 - val_acc: 0.9117\n","\n","epoch 14/30\n","188/188 [==============================] - 51s 265ms/step - train_acc: 0.9150 - val_acc: 0.90901\n","\n","epoch 15/30\n","188/188 [==============================] - 51s 263ms/step - train_acc: 0.9164 - val_acc: 0.9127\n","\n","epoch 16/30\n","188/188 [==============================] - 51s 261ms/step - train_acc: 0.9197 - val_acc: 0.9090\n","\n","epoch 17/30\n","188/188 [==============================] - 51s 266ms/step - train_acc: 0.9218 - val_acc: 0.91202\n","\n","epoch 18/30\n","188/188 [==============================] - 51s 264ms/step - train_acc: 0.9211 - val_acc: 0.9227\n","\n","epoch 19/30\n","188/188 [==============================] - 51s 263ms/step - train_acc: 0.9278 - val_acc: 0.9233\n","\n","epoch 20/30\n","188/188 [==============================] - 52s 268ms/step - train_acc: 0.9229 - val_acc: 0.9230\n","\n","epoch 21/30\n","188/188 [==============================] - 51s 262ms/step - train_acc: 0.9218 - val_acc: 0.9100\n","\n","epoch 22/30\n","188/188 [==============================] - 51s 259ms/step - train_acc: 0.9300 - val_acc: 0.9243\n","\n","epoch 23/30\n","188/188 [==============================] - 52s 267ms/step - train_acc: 0.9276 - val_acc: 0.9260\n","\n","epoch 24/30\n","188/188 [==============================] - 49s 251ms/step - train_acc: 0.9279 - val_acc: 0.9250\n","\n","epoch 25/30\n","188/188 [==============================] - 51s 266ms/step - train_acc: 0.9305 - val_acc: 0.9207\n","\n","epoch 26/30\n","188/188 [==============================] - 47s 245ms/step - train_acc: 0.9303 - val_acc: 0.9203\n","\n","epoch 27/30\n","188/188 [==============================] - 52s 270ms/step - train_acc: 0.9317 - val_acc: 0.9207\n","\n","epoch 28/30\n","188/188 [==============================] - 60s 311ms/step - train_acc: 0.9327 - val_acc: 0.9233\n","\n","epoch 29/30\n","188/188 [==============================] - 51s 265ms/step - train_acc: 0.9347 - val_acc: 0.9293\n","\n","epoch 30/30\n","188/188 [==============================] - 51s 263ms/step - train_acc: 0.9355 - val_acc: 0.9247\n"]}],"source":["epochs = 30\n","for epoch in range(epochs):\n","    print(\"\\nepoch {}/{}\".format(epoch+1,epochs))\n","    pbar = keras.utils.Progbar(target=int(train_dataset.cardinality()))\n","    metrics = {}\n","\n","    # Iterate over the batches of the dataset.\n","    for step, (x_batch_train, y_true) in enumerate(train_dataset):\n","        #y_true = tf.keras.utils.to_categorical(y_batch_train,num_classes=2)\n","        with tf.GradientTape() as tape:\n","            y_pred=model(x_batch_train) # $ better design needed.\n","            # y_pred is prob. dist.\n","            loss_value = loss_fn(y_true,y_pred) # loss computation\n","        grads = tape.gradient(loss_value, model.trainable_weights) # back prop\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights)) # weight update\n","\n","        # Update training metric.\n","        train_acc_metric.update_state(y_true, y_pred)\n","        metrics.update({'train_acc':train_acc_metric.result()})\n","        pbar.update(step+1, values=metrics.items(), finalize=False)\n","\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in val_dataset:\n","      #y_batch_val=tf.keras.utils.to_categorical(y_batch_val,num_classes=2)\n","      val_pred = model(x_batch_val) # $ better design needed\n","      # Update val metrics\n","      val_acc_metric.update_state(y_batch_val, val_pred)\n","\n","    metrics.update({'val_acc':val_acc_metric.result()})\n","    \n","    pbar.update(step+1, values=metrics.items(), finalize=True)\n","    \n","    # Reset training & val metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","    val_acc_metric.reset_states()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.3 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
