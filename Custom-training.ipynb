{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrsRESNET1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wkl0rzN69JYr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "3pDr2xRMbCIL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading data.\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "#train data\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
        "                                                            shuffle=True,\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            image_size=IMG_SIZE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wWYiNPu9lX_",
        "outputId": "7bd1c685-2ebd-4066-ffb1-cddd206a6650"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n",
            "68616192/68606236 [==============================] - 1s 0us/step\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation model.\n",
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
        "                                                                 shuffle=True,\n",
        "                                                                 batch_size=BATCH_SIZE,\n",
        "                                                                 image_size=IMG_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exbju2fEby1Q",
        "outputId": "684e9326-eaf5-47de-ec51-115b0b5636d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating test data.\n",
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "test_dataset = validation_dataset.take(val_batches // 5)\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)"
      ],
      "metadata": {
        "id": "ZbUHfENbcxry"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jy_OIGmc48b",
        "outputId": "2fe79ae8-16ad-4031-9463-3aabd041a7b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation batches: 26\n",
            "Number of test batches: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimization parameter setting.\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "uMVn_NQpdGI-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data augmentation layer.\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "MXYHQFAleTZo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing specific to resnet.\n",
        "preprocess_input = tf.keras.applications.resnet.preprocess_input"
      ],
      "metadata": {
        "id": "1nHr3-nLfSCE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#base resnet model.\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9AH5f3jfw0Q",
        "outputId": "340a919f-a696-4494-8e37-5beecc7976e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "rUP-ZGuFhM5q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the features to a single 2048-element vector per image.\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
      ],
      "metadata": {
        "id": "ZxRRpg5rh17w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply a tf.keras.layers.Dense layer to convert these features into a single prediction per image. \n",
        "prediction_layer = tf.keras.layers.Dense(1)"
      ],
      "metadata": {
        "id": "Z7bFzXhNie3D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_inputs = base_model.layers[0].input\n",
        "base_outputs = base_model.layers[-26].output\n",
        "z = global_average_layer(base_outputs)\n",
        "z = tf.keras.layers.Dropout(0.2)(z)\n",
        "classifier = prediction_layer(z)\n",
        "tmp_model = keras.Model(inputs=base_inputs, outputs=classifier)"
      ],
      "metadata": {
        "id": "sy4-7LckIaPN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "outputs = tmp_model(x, training=False)\n",
        "new_model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "x7lhsRfmFVck"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"customize training loop.\"\"\"\n",
        "\n",
        "# Instantiate an optimizer to train the model.\n",
        "base_learning_rate = 0.0001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
        "# Instantiate a loss function.\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Prepare the metrics.\n",
        "train_acc_metric = keras.metrics.BinaryAccuracy()\n",
        "val_acc_metric = keras.metrics.BinaryAccuracy()"
      ],
      "metadata": {
        "id": "UFyOAK1OP7AA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = new_model(x_batch_train, training=True)\n",
        "            loss_value = loss_fn(y_batch_train, logits)\n",
        "        grads = tape.gradient(loss_value, new_model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, new_model.trainable_weights))\n",
        "\n",
        "        # Update training metric.\n",
        "        train_acc_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "        \"\"\"# Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\"\"\"\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in validation_dataset:\n",
        "        val_logits = new_model(x_batch_val, training=False)\n",
        "        # Update val metrics\n",
        "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dqrDxJ1T3rf",
        "outputId": "3725d6f3-0cc0-4ffb-855b-d1483ec18d38"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training acc over epoch: 0.5809\n",
            "Validation acc: 0.7007\n",
            "Time taken: 703.86s\n",
            "\n",
            "Start of epoch 1\n",
            "Training acc over epoch: 0.6890\n",
            "Validation acc: 0.7993\n",
            "Time taken: 692.57s\n",
            "\n",
            "Start of epoch 2\n",
            "Training acc over epoch: 0.7579\n",
            "Validation acc: 0.8558\n",
            "Time taken: 693.08s\n",
            "\n",
            "Start of epoch 3\n",
            "Training acc over epoch: 0.8090\n",
            "Validation acc: 0.8894\n",
            "Time taken: 684.94s\n",
            "\n",
            "Start of epoch 4\n",
            "Training acc over epoch: 0.8294\n",
            "Validation acc: 0.9099\n",
            "Time taken: 683.60s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"custome training with tf.function for better performance as a static graph \n",
        "enables the framework to apply global performance optimizations.\"\"\"\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = new_model(x, training=True)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss_value, new_model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, new_model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value\n",
        "\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = new_model(x, training=False)\n",
        "    val_acc_metric.update_state(y, val_logits)"
      ],
      "metadata": {
        "id": "_3_paAMjr_37"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in validation_dataset:\n",
        "        test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg5uMME1mpP6",
        "outputId": "2a42683c-eb91-4b45-e8ef-afe20c1ad50f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training acc over epoch: 0.5818\n",
            "Validation acc: 0.6995\n",
            "Time taken: 241.41s\n",
            "\n",
            "Start of epoch 1\n",
            "Training acc over epoch: 0.6835\n",
            "Validation acc: 0.8125\n",
            "Time taken: 220.22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Much faster, isn't it?."
      ],
      "metadata": {
        "id": "5PpoWVjenh9f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}